{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few images and labels from the training set:\n",
      "Image 1 shape: (9, 9, 5), Label: [0. 0. 1.]\n",
      "Image 2 shape: (9, 9, 5), Label: [1. 0. 0.]\n",
      "Image 3 shape: (9, 9, 5), Label: [1. 0. 0.]\n",
      "Image 4 shape: (9, 9, 5), Label: [0. 1. 0.]\n",
      "Image 5 shape: (9, 9, 5), Label: [1. 0. 0.]\n",
      "(84420, 9, 9, 5)\n",
      "\n",
      "First few images and labels from the test set:\n",
      "Image 1 shape: (9, 9, 5), Label: [0. 1. 0.]\n",
      "Image 2 shape: (9, 9, 5), Label: [0. 1. 0.]\n",
      "Image 3 shape: (9, 9, 5), Label: [1. 0. 0.]\n",
      "Image 4 shape: (9, 9, 5), Label: [1. 0. 0.]\n",
      "Image 5 shape: (9, 9, 5), Label: [0. 1. 0.]\n",
      "(58128, 9, 9, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import load_data  \n",
    "\n",
    "def transform(dataset, weight=1.2):\n",
    "    \"\"\"\n",
    "    Transform a dataset entry into a structured 9x9 image based on differential entropy features.\n",
    "    \"\"\"\n",
    "    im = np.zeros([9, 9])\n",
    "\n",
    "    im[0, 3:6] = dataset[0:3]\n",
    "    im[1, [3, 5]] = dataset[3:5]\n",
    "    im[2] = dataset[5:14]  # Fills the whole second row\n",
    "    im[3] = dataset[14:23]  # Fills the whole third row\n",
    "    im[4] = dataset[23:32]  # Fills the whole fourth row\n",
    "    im[5] = dataset[32:41]  # Fills the whole fifth row\n",
    "    im[6] = dataset[41:50]  # Fills the whole sixth row\n",
    "    im[7, 1:8] = dataset[50:57]\n",
    "    im[8, 2:7] = dataset[57:62]\n",
    "\n",
    "    # Apply weighting to specified indices\n",
    "    #for i in [3, 4, 5, 6]:\n",
    "    #    im[i, [0, 8]] *= weight\n",
    "    \n",
    "    return im.reshape(9, 9, 1)\n",
    "\n",
    "def convert_to_images(data, labels):\n",
    "    \"\"\"\n",
    "    Convert the numerical EEG data into images.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    normalized_data = scaler.fit_transform(data.T).T\n",
    "    \n",
    "    images = []\n",
    "    for i in range(normalized_data.shape[0]):\n",
    "        # Concatenate transformed segments to create a multi-channel image representation\n",
    "        images.append(np.concatenate([transform(normalized_data[i][j:j+62], 1.2) for j in range(0, 310, 62)], axis=2))\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load data, transform it to images, shuffle, and save the processed data.\n",
    "    \"\"\"\n",
    "    # Load data using the structure defined in your load_data module\n",
    "    data = load_data.read_data_sets(one_hot=True)\n",
    "    \n",
    "    # Transform training data to images\n",
    "    train_imgs, train_labels = convert_to_images(data.train.data, data.train.labels)\n",
    "    # Shuffle the training data\n",
    "    train_indices = np.random.permutation(len(train_imgs))\n",
    "    train_imgs, train_labels = train_imgs[train_indices], train_labels[train_indices]\n",
    "    \n",
    "    # Transform test data to images\n",
    "    test_imgs, test_labels = convert_to_images(data.test.data, data.test.labels)\n",
    "    # Shuffle the test data\n",
    "    test_indices = np.random.permutation(len(test_imgs))\n",
    "    test_imgs, test_labels = test_imgs[test_indices], test_labels[test_indices]\n",
    "    \n",
    "    # Print the shape of the first few images and labels in the training set\n",
    "    print(\"First few images and labels from the training set:\")\n",
    "    for i in range(min(5, len(train_imgs))):  \n",
    "        print(f\"Image {i+1} shape: {train_imgs[i].shape}, Label: {train_labels[i]}\")\n",
    "    print(train_imgs.shape)\n",
    "    \n",
    "    # Print the shape of the first few images and labels in the test set\n",
    "    print(\"\\nFirst few images and labels from the test set:\")\n",
    "    for i in range(min(5, len(test_imgs))):  \n",
    "        print(f\"Image {i+1} shape: {test_imgs[i].shape}, Label: {test_labels[i]}\")\n",
    "    print(test_imgs.shape)\n",
    "\n",
    "    # Save the transformed and shuffled training data\n",
    "    with open('./data/train_images.pkl', 'wb') as f:\n",
    "        pickle.dump({'data': train_imgs, 'label': train_labels}, f)\n",
    "\n",
    "    # Save the transformed and shuffled test data\n",
    "    with open('./data/test_images.pkl', 'wb') as f:\n",
    "        pickle.dump({'data': test_imgs, 'label': test_labels}, f)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
